{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 04\n",
    "# Pipelines and OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create three custom transformers, the first two out of which will be used within a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "1. `FeatureExtractor()` class:\n",
    " - Takes a dataframe with `uid`, `labname`, `numTrials`, `timestamp` from the file [`checker_submits.csv`](https://drive.google.com/file/d/14voc4fNJZiLEFaZyd8nEG-lQt5JjatYw/view?usp=sharing).\n",
    " - Extracts `hour` from `timestamp`.\n",
    " - Extracts `weekday` from `timestamp` (numbers).\n",
    " - Drops the `timestamp` column.\n",
    " - Returns the new dataframe.\n",
    "\n",
    "\n",
    "2. `MyOneHotEncoder()` class:\n",
    " - Takes the dataframe from the result of the previous transformation and the name of the target column.\n",
    " - Identifies all the categorical features and transforms them with `OneHotEncoder()`. If the target column is categorical too, then the transformation should not apply to it.\n",
    " - Drops the initial categorical features.\n",
    " - Returns the dataframe with the features and the series with the target column.\n",
    "\n",
    "\n",
    "3. `TrainValidationTest()` class:\n",
    " - Takes `X` and `y`.\n",
    " - Returns `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` (`test_size=0.2`, `random_state=21`, `stratified`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df['hour'] = pd.to_datetime(df['timestamp']).dt.hour\n",
    "        df['dayofweek'] = pd.to_datetime(df['timestamp']).dt.weekday\n",
    "        df.drop(columns=['timestamp'], inplace=True)\n",
    "        return df\n",
    "\n",
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_column):\n",
    "        self.target_column = target_column\n",
    "        self.encoder = OneHotEncoder()\n",
    "    \n",
    "    def fit(self, df):\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "        self.categorical_cols = [col for col in categorical_cols if col != self.target_column]\n",
    "        self.encoder.fit(df[self.categorical_cols])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        encoded_features = self.encoder.transform(df[self.categorical_cols])\n",
    "        encoded_df = pd.DataFrame(encoded_features.toarray(), columns=self.encoder.get_feature_names_out(input_features=self.categorical_cols))\n",
    "        df.drop(columns=self.categorical_cols, inplace=True)\n",
    "        return pd.concat([df.reset_index(drop=True), encoded_df], axis=1)\n",
    "\n",
    "class TrainValidationTest(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        X = df.drop(columns='dayofweek')\n",
    "        y = df['dayofweek']\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)\n",
    "        X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=21, stratify=y_temp)\n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ModelSelection()` class\n",
    "\n",
    " - Takes a list of `GridSearchCV` instances and a dict where the keys are the indexes from that list and the values are the names of the models, the example is below in the reverse order (from high-level to low-level perspective):\n",
    "\n",
    "```\n",
    "ModelSelection(grids, grid_dict)\n",
    "\n",
    "grids = [gs_svm, gs_tree, gs_rf]\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=2, n_jobs=jobs), where jobs you can specify by yourself\n",
    "\n",
    "svm_params = [{'kernel':('linear', 'rbf', 'sigmoid'), 'C':[0.01, 0.1, 1, 1.5, 5, 10], 'gamma': ['scale', 'auto'], 'class_weight':('balanced', None), 'random_state':[21], 'probability':[True]}]\n",
    "```\n",
    "\n",
    " - Method `choose()` takes `X_train`, `y_train`, `X_valid`, `y_valid` and returns the name of the best classifier among all the models on the validation set\n",
    " - Method `best_results()` returns a dataframe with the columns `model`, `params`, `valid_score` where the rows are the best models within each class of models.\n",
    "\n",
    "```\n",
    "model\tparams\tvalid_score\n",
    "0\tSVM\t{'C': 10, 'class_weight': None, 'gamma': 'auto...\t0.772727\n",
    "1\tDecision Tree\t{'class_weight': 'balanced', 'criterion': 'gin...\t0.801484\n",
    "2\tRandom Forest\t{'class_weight': None, 'criterion': 'entropy',...\t0.855288\n",
    "```\n",
    "\n",
    " - When you iterate through the parameters of a model class, print the name of that class and show the progress using `tqdm.notebook`, in the end of the cycle print the best model of that class.\n",
    "\n",
    "```\n",
    "Estimator: SVM\n",
    "100%\n",
    "125/125 [01:32<00:00, 1.36it/s]\n",
    "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
    "Best training accuracy: 0.773\n",
    "Validation set accuracy score for best params: 0.878 \n",
    "\n",
    "Estimator: Decision Tree\n",
    "100%\n",
    "57/57 [01:07<00:00, 1.22it/s]\n",
    "Best params: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 21, 'random_state': 21}\n",
    "Best training accuracy: 0.801\n",
    "Validation set accuracy score for best params: 0.867 \n",
    "\n",
    "Estimator: Random Forest\n",
    "100%\n",
    "284/284 [06:47<00:00, 1.13s/it]\n",
    "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 22, 'n_estimators': 50, 'random_state': 21}\n",
    "Best training accuracy: 0.855\n",
    "Validation set accuracy score for best params: 0.907 \n",
    "\n",
    "Classifier with best validation set accuracy: Random Forest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection:\n",
    "    def __init__(self, grids, grid_dict):\n",
    "        self.grids = grids\n",
    "        self.grid_dict = grid_dict\n",
    "    \n",
    "    def best_results(self):\n",
    "        results = []\n",
    "        for i, grid in enumerate(self.grids):\n",
    "            best_params = grid.best_params_\n",
    "            best_score = grid.best_score_\n",
    "            model_name = self.grid_dict[i]\n",
    "            results.append({'model': model_name, 'params': best_params, 'valid_score': best_score})\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    def choose(self, X_train, y_train, X_valid, y_valid):\n",
    "        best_model = None\n",
    "        best_score = 0\n",
    "        for i, grid in enumerate(self.grids):\n",
    "            print(f\"Estimator: {self.grid_dict[i]}\")\n",
    "            for params in tqdm(grid.param_grid, desc=\"Grid search progress\"):\n",
    "                grid.set_params(param_grid=params)\n",
    "                grid.fit(X_train, y_train)\n",
    "                print(f\"Best params: {grid.best_params_}\")\n",
    "                print(f\"Best training accuracy: {grid.best_score_:.3f}\")\n",
    "                score = grid.score(X_valid, y_valid)\n",
    "                print(f\"Validation set accuracy score for best params: {score:.3f}\\n\")\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_model = self.grid_dict[i]\n",
    "                    best_estimator = grid.best_estimator_\n",
    "        print(f\"Classifier with best validation set accuracy: {best_model}\")\n",
    "        return best_model, best_estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Finalize()` class\n",
    " - Takes an estimator.\n",
    " - Method `final_score()` takes `X_train`, `y_train`, `X_test`, `y_test` and returns the accuracy of the model as in the example below:\n",
    "```\n",
    "final.final_score(X_train, y_train, X_test, y_test)\n",
    "Accuracy of the final model is 0.908284023668639\n",
    "```\n",
    " - Method `save_model()` takes a path, saves the model to this path and prints that the model was successfully saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finalize:\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def final_score(self, X_train, y_train, X_test, y_test):\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        y_pred = self.estimator.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f'Accuracy of the final model is {accuracy}')\n",
    "        return accuracy\n",
    "\n",
    "    def save_model(self, path):\n",
    "        dump(self.estimator, path)\n",
    "        print(f'The model was successfully saved to {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the data from the file (****name of file****).\n",
    "2. Create the preprocessing pipeline that consists of two custom transformers: `FeatureExtractor()` and `MyOneHotEncoder()`:\n",
    "```\n",
    "preprocessing = Pipeline([('feature_extractor', FeatureExtractor()), ('onehot_encoder', MyOneHotEncoder('dayofweek'))])\n",
    "```\n",
    "3. Use that pipeline and its method `fit_transform()` on the initial dataset.\n",
    "```\n",
    "data = preprocessing.fit_transform(df)\n",
    "```\n",
    "4. Get `X_train`, `X_valid`, `X_test`, `y_train`, `y_valid`, `y_test` using `TrainValidationTest()` and the result of the pipeline.\n",
    "5. Create an instance of `ModelSelection()`, use the method `choose()` applying it to the models that you want and parameters that you want, get the dataframe of the best results.\n",
    "6. create an instance of `Finalize()` with your best model, use method `final_score()` and save the model in the format: `name_of_the_model_{accuracy on test dataset}.sav`.\n",
    "\n",
    "That is it, congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/checker_submits.csv')\n",
    "\n",
    "preprocessing = Pipeline([\n",
    "    ('feature_extractor', FeatureExtractor()),\n",
    "    ('onehot_encoder', MyOneHotEncoder('dayofweek')\n",
    ")])\n",
    "\n",
    "data = preprocessing.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test, y_train, y_valid, y_test = TrainValidationTest().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=21)\n",
    "tree = DecisionTreeClassifier(random_state=21)\n",
    "rf = RandomForestClassifier(random_state=21)\n",
    "\n",
    "svm_params = [\n",
    "    {\n",
    "        'kernel':('linear', 'rbf', 'sigmoid'),\n",
    "        'C':[0.01, 0.1, 1, 1.5, 5, 10],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'class_weight':('balanced', None),\n",
    "        'random_state':[21],\n",
    "        'probability':[True]\n",
    "    }\n",
    "]\n",
    "\n",
    "tree_params = [\n",
    "    {\n",
    "        'max_depth': range(1, 50),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'criterion': ['entropy', 'gini']\n",
    "    }\n",
    "]\n",
    "\n",
    "rf_params = [\n",
    "    {\n",
    "        'n_estimators': [5, 10, 50, 100],\n",
    "        'max_depth': range(1, 50),\n",
    "        'class_weight': ['balanced', None],\n",
    "        'criterion': ['entropy', 'gini']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: SVM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23b8b845c374c8285b57e5d537e4dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid search progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True, 'random_state': 21}\n",
      "Best training accuracy: 0.809\n",
      "Validation set accuracy score for best params: 0.870\n",
      "\n",
      "Estimator: Decision Tree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af3b1d6374d45beb19b1aa58fb7f9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid search progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': None, 'criterion': 'gini', 'max_depth': 17}\n",
      "Best training accuracy: 0.829\n",
      "Validation set accuracy score for best params: 0.811\n",
      "\n",
      "Estimator: Random Forest\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa55e96e9eb94be2b8dfad8b74de3186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid search progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 26, 'n_estimators': 100}\n",
      "Best training accuracy: 0.877\n",
      "Validation set accuracy score for best params: 0.917\n",
      "\n",
      "Classifier with best validation set accuracy: Random Forest\n"
     ]
    }
   ],
   "source": [
    "jobs = -1\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=svm, param_grid=svm_params, scoring='accuracy', cv=2, n_jobs=jobs)\n",
    "gs_tree = GridSearchCV(estimator=tree, param_grid=tree_params, scoring='accuracy', cv=2, n_jobs=jobs)\n",
    "gs_rf = GridSearchCV(estimator=rf, param_grid=rf_params, scoring='accuracy', cv=2, n_jobs=jobs)\n",
    "\n",
    "grid_dict = {\n",
    "    0: 'SVM',\n",
    "    1: 'Decision Tree',\n",
    "    2: 'Random Forest'\n",
    "}\n",
    "\n",
    "selector = ModelSelection([gs_svm, gs_tree, gs_rf], grid_dict)\n",
    "best_model, best_estimator = selector.choose(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>params</th>\n",
       "      <th>valid_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'gamma': 'auto...</td>\n",
       "      <td>0.809347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.829377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.876855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                                             params   \n",
       "0            SVM  {'C': 10, 'class_weight': None, 'gamma': 'auto...  \\\n",
       "1  Decision Tree  {'class_weight': None, 'criterion': 'gini', 'm...   \n",
       "2  Random Forest  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "\n",
       "   valid_score  \n",
       "0     0.809347  \n",
       "1     0.829377  \n",
       "2     0.876855  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.best_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the final model is 0.9467455621301775\n",
      "The model was successfully saved to ../data/Random Forest_0.9467.sav\n"
     ]
    }
   ],
   "source": [
    "finalize = Finalize(best_estimator)\n",
    "accuracy = finalize.final_score(X_train, y_train, X_test, y_test)\n",
    "model_name = f'../data/{best_model}_{accuracy:.4f}.sav'\n",
    "finalize.save_model(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
